"""
Merges the user, survey and vital data into one consistent input file for further evaluation.

Specifically, each survey response is combined with the average vital data in the 4 weeks prior to
providing the response. That way the vital observation aligns with the wording of the survey
questions.
"""

from pathlib import Path
import pandas as pd
import numpy as np
import hydra


def get_dummy_entries(surveys, vitals):
    """
    Create a sequence of dummy entries at which the average vital data in the past 28 days will be
    computed.

    This needs to be done since vital data is not necessary available at the day of responding to a
    survey. In that case a NaN entry for the vitals needs to be inserted on that date, so that this
    entry can serve as the anchor point for computing a rolling average over the past 28 days.

    Args:
        surveys (pandas.DataFrame): The preprocessed survey data.
        vitals (pandas.DataFrame): The preprocessed vital data.

    Returns:
        pandas.DataFrame: The dummy entries.
    """
    # Get all combination of userid and date for which we have survey responses
    entries = surveys[['userid', 'date']]

    # Get the list of all device types
    devices = vitals.deviceid.unique()

    # Create a combination of userid and date for each device
    dummy_entries = pd.concat([entries] * len(devices))

    # Add each device type to each combination of users and date.
    dummy_entries['deviceid'] = np.repeat(devices, len(surveys))

    return dummy_entries


def select_subset(vitals, subset):
    """
    Select a subset of the vital data for analysis. Possible choices include 'weekend', 'weekday'
    or 'total'.

    Args:
        vitals (pandas.DataFrame): The preprocessed vital data.
        subset (str): Indicator of which vital data to return ('weekend', 'weekday' or 'total').

    Returns:
        pandas.DataFrame: The vital data for the selected temporal subset.
    """
    if subset == 'weekend':
        return vitals[vitals.weekend]
    elif subset == 'weekday':
        return vitals[~vitals.weekend]

    return vitals


def expand_vitals(vitals, dummy_entries):
    """
    Add a set of dummy entries at dates when surveys are present to the vital data.

    Args:
        vitals (pandas.DataFrame): The preprocessed vital data.
        dummy_entries (pandas.DataFrame): The dummy entries of vital data as generated by
            get_dummy_entries().

    Returns:
        pandas.DataFrame: The vital data with added dates and corresponding NaN values when survey
            data is present.
    """

    # Add the dummy entries to the list of vital data
    vitals = pd.concat([vitals, dummy_entries]).reset_index(drop=True)

    # This ensures that if an entry of the dummy entries already exists in the vital data, that
    # entry is removed.
    vitals.drop_duplicates(subset=['userid', 'date', 'deviceid'], keep='first', inplace=True)

    return vitals


def compute(surveys, vitals, min_periods, subset):
    """
    Compute 28-day rolling averages of a given subset of vital data for dates of survey responses.

    Args:
        surveys (pandas.DataFrame): The preprocessed survey data.
        vitals (pandas.DataFrame): The preprocessed vital data.
        min_periods (int): The minimum number of days with values for the rolling average to be
            computed.
        subset (_type_): _description_

    Returns:
        df: The resulting DataFrame
    """
    print('Compute 28-day rolling average of vitals for subset:', subset)

    print('Create dummy table...')
    dummy_entries = get_dummy_entries(surveys, vitals)

    print('Expand vitals with dummy table...')
    vitals = select_subset(vitals, subset)
    vitals = expand_vitals(vitals, dummy_entries)

    # Set midsleep before computing the rolling averages
    vitals['midsleep'] = 0.5 * (vitals['v53'] + vitals['v52'])

    print('Compute rolling mean and std...')
    df = vitals.set_index('date').sort_index()
    df =df.groupby(['userid', 'deviceid']).rolling('28D',  min_periods=min_periods)
    df = df['v9', 'v43', 'v65', 'v52', 'v53', 'midsleep'].agg(['mean', 'std'])

    df.columns = [f'{column[0]}{column[1]}{subset}'.replace('mean', '') for column in df.columns]
    df.reset_index(inplace=True)

    print('Done!')

    return df


def compute_zscores(df, keys, by):
    """
    Compute Z-scores of given variables for specified sub-populations.

    Args:
        df (pandas.DataFrame): DataFrame containing containing for which Z-scores are computed
        keys (list of string): The keys of the variables in the DataFrame for which Z-scores are
            computed.
        by (list of string): The criteria (keys in the DataFrame) that defines the sub-populations
            (e.g. age and/or gender)

    Returns:
        df: The DataFrame with added columns for Z-scores
    """
    for key in keys:

        # Make sure to always compute user averages first!!!
        agg = {b: 'max' for b in by}
        agg[key] = 'mean'
        user_avg = df.groupby(['user_id']).agg(agg)

        # From each user average we compute the mean and std per bucket
        avg = user_avg.groupby(by)[key].agg(['mean', 'std'])
        avg.reset_index(inplace=True)
        avg.rename(columns={'mean': key + '_demog_mean', 'std': key + '_demog_std'}, inplace=True)

        # Add the averages and std to the main data frame and compute Z-scores
        df = pd.merge(df, avg, on=by)
        df[key +'_Z'] = (df[key] - df[key + '_demog_mean']) / df[key + '_demog_std']

    return df


@hydra.main(version_base=None, config_path='../config', config_name='main.yaml')
def main(config):
    """
    Merge the survey, user and vital data into a consistent DataFrame for further analysis.

    Specifically, compute 28-day rolling averages of vital data for weekends, weekdays and all days
    in that period at dates when survey responses are present.

    The resulting DataFrame is saved to disk.
    """
    input_path = Path(config.data.interim)
    output_path = Path(config.data.processed)
    output_path.mkdir(parents=True, exist_ok=True)

    surveys = pd.read_feather(input_path / config.data.filenames.surveys)
    vitals = pd.read_feather(input_path / config.data.filenames.vitals)
    users = pd.read_feather(input_path / config.data.filenames.users)

    # Compute average vitals for all valid 28-day periods
    df = compute(surveys, vitals, config.process.min_days_for_averaging_vitals, subset='')

    # Append average vitals for weekends and weekdays during each 28-day period
    settings = (
        ('weekend', config.process.min_weekenddays_for_averaging_vitals),
        ('weekday', config.process.min_weekdays_for_averaging_vitals)
    )

    for subset, min_periods in settings:
        df_subset = compute(surveys, vitals, min_periods, subset)
        df = pd.merge(df, df_subset, on=['userid', 'deviceid', 'date'])

    # Compute weekend/weekday differences
    for vital in ('v9', 'v65', 'v43', 'v52', 'v53', 'midsleep'):
        df[f'{vital}difference'] = df[f'{vital}weekend'] - df[f'{vital}weekday']
        df[f'{vital}difference_relative'] = df[f'{vital}weekend'] / df[f'{vital}weekday'] - 1

    df.rename(columns={'midsleepdifference': 'social_jetlag'}, inplace=True)

    # Add sleep duration in hours
    df['v43_hr'] = df.v43 / 60

    df = pd.merge(surveys, df, on=['userid', 'date'])
    df = pd.merge(users, df, left_on='user_id', right_on='userid')

    df = compute_zscores(
        df,
        keys=['q49', 'q50', 'q54', 'q55', 'q56', 'total_wellbeing'],
        by=['salutation', 'birth_date']
    )

    df.to_feather(output_path / config.data.filenames.merged_data)


if __name__ == "__main__":
    main() # pylint: disable=E1120
